---
title: The Continuous Transformer 
presentation_date: September 27, 2021
img: /assets/img/talks/transformer_mask.png
category: research talks 
slides: true
slides_keynote: https://drive.google.com/file/d/1cx4DWbD6tPtdXiMLbntf3iZFE8sy-_-f/view?usp=sharing
slides_ppt: https://docs.google.com/presentation/d/1_hSGr7HCO3C1AwHUVwoH7WtJnv0HZxTl/edit?usp=sharing&ouid=107160263751202522175&rtpof=true&sd=true
slides_pdf: https://drive.google.com/file/d/1081RDaC8B31TOf-tte_iASfYHhyokyJn/view?usp=sharing
summary: A work-in-progress (WIP) talk to the Beam lab about my progress on creating the first Continuous Transformer â€“ an architecture that can learn contextualized embeddings of both discrete and continuous data.
---

---
title: Deep Blue
authors: Murray Campbell, Joseph Hoane Jr., Feng-hsiung
paper_year: 2002
presentation_date: September 13, 2021
img: /assets/img/talks/kasparov_vs_deep_blue.jpeg
category: journal clubs 
paper_url: https://www.sciencedirect.com/science/article/pii/S0004370201001291
slides: true
slides_keynote: Deep Blue presentation.key
slides_ppt: Deep Blue presentation.pptx
slides_pdf: Deep Blue presentation.pdf
summary: A review of the Deep Blue II chess engine made by IBM in the 1990s, including a visual beginner-friendly walk-through of the minimax algorithm and alpha-beta pruning that made up the core of the AI. Chess tutorial not included, sad!
# Can add a blog link to a relevant blog post here.
# Can also add a code link to relevant code here.
# Can even add a poster link.
---